{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 7 - Tensorflow2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manuel Rodas - 21509 / Sebastian Solorzano - 21826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Optimización de Hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cambie el número de observaciones a 100,000. Este no es un hiperparámetro pero puede afectar el rendimiento del modelo. ¿Qué ocurre?\n",
    "    - Al cambiar a 100,000 observaciones, el modelo de entrenamiento tendrá más datos, con esto mejora el rendimineto del modelo en la presición y generalización, aunque también existe el riesgo de sobreajuste ya que el modelo puede ajustar los datos de entrenamiento específicos y no generaliza bien a datos nuevos.\n",
    "\n",
    "2. Experimente con diferentes valores para la tasa de aprendizaje. Los valores como 0.0001, 0.001, 0.1, 1 son interesantes para observar. Prueba también cambiando el número de épocas (50, 100, 200). ¿Qué diferencias se observan? ¿Se comporta bien el algoritmo?\n",
    "    - Tasa de aprendizaje: Con una tasa de aprendizaje baja (0.0001) el entrenamiento de datos es lento y requiere de más épocas para converger, con una tasa de aprendizaje media (0.001-0.1) dentro de este rango son los mejores valores para un entrenamiento rápido y converger de manera eficiente, con una tasa de aprendizaje alta (0.1-1.0) puede provocar que el modelo diverja y en este caso provocó que los valores de peso y sesgo se volvieran 'nan', al igual que los valores de predicción se vuelva 'nan'.\n",
    "    - Número de épocas: Con un número de épocas bajo (50) puede llegar a no ser suficiente para que el modelo converja, con un número de épocas medio (100) es el mejor valor para que el modelo converja de manera eficiente, con un número de épocas alto (200) es bueno para que el modelo converja, aunque puede provocar sobreajuste.\n",
    "\n",
    "3. Cambie la función de pérdida. ¿Cómo se comparan los resultados al cambiar la función de pérdida? Una función alternativa es la “Huber Loss”.\n",
    "    - Se pueden observar diferencias en el rendimiento del modelo. La función de pérdida de Huber es menos sensible a los valores atípicos en los datos en comparación con la función de pérdida cuadrática, ya que utiliza una función de pérdida cuadrática para errores pequeños y una función lineal para errores grandes. \n",
    "\n",
    "4. Evalúe cómo estos cambios afectan la precisión y la pérdida del modelo.\n",
    "    - Los cambios tienen un impacto en la precisión y la pérdida del modelo. Una tasa de aprendizaje alta puede acelerar la convergencia del modelo al principio, pero si es demasiado alta, puede provocar que los valores de peso y sesgo se vuelvan \"nan\", lo que indica una divergencia en el proceso. Esto puede resultar en una precisión más baja y una pérdida más alta en comparación con una tasa de aprendizaje más moderada. Del mismo modo, un número bajo de épocas puede impedir que el modelo alcance su máximo potencial, lo que resulta en una precisión más baja. En cuanto a la función de pérdida, elegir la función de pérdida de Huber para datos con valores atípicos, mejora el modelo y, por lo tanto, su precisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Validación Cruzada:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implemente una técnica de validación cruzada para evaluar la estabilidad y la generalización del modelo.\n",
    "    - Se implementó la validación cruzada utilizando la clase KFold del módulo sklearn.model_selection. Específicamente, se ha configurado la validación cruzada con 3 pliegues (n_splits=5). En cada iteración, los datos se dividen en conjuntos de entrenamiento y validación. Luego, el modelo se entrena en el conjunto de entrenamiento y se evalúa en el conjunto de validación correspondiente.\n",
    "2. Resultados de precisión y pérdida para cada iteración de la validación cruzada.\n",
    "    - Iteración 1: Pérdida = 0.38, Precisión = 0.52\n",
    "    - Iteración 2: Pérdida = 0.37, Precisión = 0.52\n",
    "    - Iteración 3: Pérdida = 0.33, Precisión = 0.54\n",
    "3. Métricas de precisión y pérdida de la validación cruzada.\n",
    "    - Precisión media: 0.131610577305158\n",
    "    - Desviación estándar de precisión: 0.2279819908387974\n",
    "    - Pérdida media: 0.3523204882939657\n",
    "    - Desviación estándar de pérdida: 0.026526961826111136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Interpretación de Resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resultados de precision y pérdida:\n",
    "\n",
    "    - Precision media de la validación cruzada: 0.131610577305158, lo cual es un dato bastante bajo, con esto podemos deducir que el modelo tiende a no tener un gran rendimiento en terminos de presicion. Esto se puede deber a que el modelo no es lo suficientemente complejo para capturar la relación entre las características de entrada y la variable objetivo. Mientras que la desviacion estandar de la precision es de 0.2279819908387974, este dato llega a ser bastante alto, lo cual indica que la precisión varía significativamente entre las diferentes iteraciones de la validación cruzada.\n",
    "\n",
    "    - La perdida media de la validación cruzada es de 0.3523204882939657, lo cual es un dato bastante alto, con esto podemos deducir que el modelo no es lo suficientemente bueno para minimizar la pérdida, ademas de mostrarnos que el modelo tiene un rendimiento bastante constante. Mientras que la desviación estándar de la pérdida es de 0.026526961826111136, este dato llega a ser bastante bajo, lo cual indica que la pérdida varía poco entre las diferentes iteraciones de la validación cruzada.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados indican que el modelo llega a presenta un nivel de pérdida bastante consistente a lo largo de las iteraciones de la validación cruzada, viendose en una variabilidad baja, por lo que se sugiere que el modelo es estable en este sentido. Pero, en la precisión es bastante baja, y la alta desviación estándar muestra que el modelo es inconsistente en su capacidad para hacer predicciones precisas.\n",
    "\n",
    "Con esto en mente podemos ver que esto se debe a algun problema en un ajuste insuficiente o algun error cuando se realizo el entrenamiento que generaron datos inadecuados, o un problema con el propio modelo o la estrategia de entrenamiento.Con esto podemos plantear que para mejorar el rendimiento del modelo, se podria explorar ajustes en la arquitectura del modelo, el uso de funciones de activación, hiperparámetros, y calidad de los datos. Tambien es importante que tomemos en cuenta que se puede considerar el uso de técnicas de preprocesamiento adicionales o experimentación con diferentes modelos para mejorar la precisión y reducir la variabilidad."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

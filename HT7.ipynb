{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 7 - Tensorflow2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manuel Rodas - 21509 / Sebastian Solorzano - 21826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Optimización de Hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cambie el número de observaciones a 100,000. Este no es un hiperparámetro pero puede afectar el rendimiento del modelo. ¿Qué ocurre?\n",
    "    - Al cambiar a 100,000 observaciones, el modelo de entrenamiento tendrá más datos, con esto mejora el rendimineto del modelo en la presición y generalización, aunque también existe el riesgo de sobreajuste ya que el modelo puede ajustar los datos de entrenamiento específicos y no generaliza bien a datos nuevos.\n",
    "\n",
    "2. Experimente con diferentes valores para la tasa de aprendizaje. Los valores como 0.0001, 0.001, 0.1, 1 son interesantes para observar. Prueba también cambiando el número de épocas (50, 100, 200). ¿Qué diferencias se observan? ¿Se comporta bien el algoritmo?\n",
    "    - Tasa de aprendizaje: Con una tasa de aprendizaje baja (0.0001) el entrenamiento de datos es lento y requiere de más épocas para converger, con una tasa de aprendizaje media (0.001-0.1) dentro de este rango son los mejores valores para un entrenamiento rápido y converger de manera eficiente, con una tasa de aprendizaje alta (0.1-1.0) puede provocar que el modelo diverja y en este caso provocó que los valores de peso y sesgo se volvieran 'nan', al igual que los valores de predicción se vuelva 'nan'.\n",
    "    - Número de épocas: Con un número de épocas bajo (50) puede llegar a no ser suficiente para que el modelo converja, con un número de épocas medio (100) es el mejor valor para que el modelo converja de manera eficiente, con un número de épocas alto (200) es bueno para que el modelo converja, aunque puede provocar sobreajuste.\n",
    "\n",
    "3. Cambie la función de pérdida. ¿Cómo se comparan los resultados al cambiar la función de pérdida? Una función alternativa es la “Huber Loss”.\n",
    "    - Se pueden observar diferencias en el rendimiento del modelo. La función de pérdida de Huber es menos sensible a los valores atípicos en los datos en comparación con la función de pérdida cuadrática, ya que utiliza una función de pérdida cuadrática para errores pequeños y una función lineal para errores grandes. \n",
    "\n",
    "4. Evalúe cómo estos cambios afectan la precisión y la pérdida del modelo.\n",
    "    - Los cambios tienen un impacto en la precisión y la pérdida del modelo. Una tasa de aprendizaje alta puede acelerar la convergencia del modelo al principio, pero si es demasiado alta, puede provocar que los valores de peso y sesgo se vuelvan \"nan\", lo que indica una divergencia en el proceso. Esto puede resultar en una precisión más baja y una pérdida más alta en comparación con una tasa de aprendizaje más moderada. Del mismo modo, un número bajo de épocas puede impedir que el modelo alcance su máximo potencial, lo que resulta en una precisión más baja. En cuanto a la función de pérdida, elegir la función de pérdida de Huber para datos con valores atípicos, mejora el modelo y, por lo tanto, su precisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Validación Cruzada:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implemente una técnica de validación cruzada para evaluar la estabilidad y la generalización del modelo.\n",
    "    - Se implementó la validación cruzada utilizando la clase KFold del módulo sklearn.model_selection. Específicamente, se ha configurado la validación cruzada con 3 pliegues (n_splits=5). En cada iteración, los datos se dividen en conjuntos de entrenamiento y validación. Luego, el modelo se entrena en el conjunto de entrenamiento y se evalúa en el conjunto de validación correspondiente.\n",
    "2. Resultados de precisión y pérdida para cada iteración de la validación cruzada.\n",
    "    - Iteración 1: Pérdida = 0.38, Precisión = 0.52\n",
    "    - Iteración 2: Pérdida = 0.37, Precisión = 0.52\n",
    "    - Iteración 3: Pérdida = 0.33, Precisión = 0.54\n",
    "3. Métricas de precisión y pérdida de la validación cruzada.\n",
    "    - Precisión media: 0.131610577305158\n",
    "    - Desviación estándar de precisión: 0.2279819908387974\n",
    "    - Pérdida media: 0.3523204882939657\n",
    "    - Desviación estándar de pérdida: 0.026526961826111136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Interpretación de Resultados:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
